{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamlorddanny/CNN_waste_segregation_assignment/blob/main/CNN_Assignment_PrakashDannySagar1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf5lYawIw8tE"
      },
      "source": [
        "# **Waste Material Segregation for Improving Waste Management**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY1InIbkw80B"
      },
      "source": [
        "## **Objective**\n",
        "\n",
        "The objective of this project is to implement an effective waste material segregation system using convolutional neural networks (CNNs) that categorises waste into distinct groups. This process enhances recycling efficiency, minimises environmental pollution, and promotes sustainable waste management practices.\n",
        "\n",
        "The key goals are:\n",
        "\n",
        "* Accurately classify waste materials into categories like cardboard, glass, paper, and plastic.\n",
        "* Improve waste segregation efficiency to support recycling and reduce landfill waste.\n",
        "* Understand the properties of different waste materials to optimise sorting methods for sustainability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZGTCfyUxalZ"
      },
      "source": [
        "## **Data Understanding**\n",
        "\n",
        "The Dataset consists of images of some common waste materials.\n",
        "\n",
        "1. Food Waste\n",
        "2. Metal\n",
        "3. Paper\n",
        "4. Plastic\n",
        "5. Other\n",
        "6. Cardboard\n",
        "7. Glass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZJtmMnzQjAr"
      },
      "source": [
        "**Data Description**\n",
        "\n",
        "* The dataset consists of multiple folders, each representing a specific class, such as `Cardboard`, `Food_Waste`, and `Metal`.\n",
        "* Within each folder, there are images of objects that belong to that category.\n",
        "* However, these items are not further subcategorised. <br> For instance, the `Food_Waste` folder may contain images of items like coffee grounds, teabags, and fruit peels, without explicitly stating that they are actually coffee grounds or teabags."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBFt43WDzWSJ"
      },
      "source": [
        "## **1. Load the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dfy0rjJ1yzFl"
      },
      "source": [
        "Load and unzip the dataset zip file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N35LLuWXzUQH"
      },
      "source": [
        "**Import Necessary Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DmZo7m1-J_Ou"
      },
      "outputs": [],
      "source": [
        "# Recommended versions:\n",
        "\n",
        "# numpy version: 1.26.4\n",
        "# pandas version: 2.2.2\n",
        "# seaborn version: 0.13.2\n",
        "# matplotlib version: 3.10.0\n",
        "# PIL version: 11.1.0\n",
        "# tensorflow version: 2.18.0\n",
        "# keras version: 3.8.0\n",
        "# sklearn version: 1.6.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4K_aYV-AeCI",
        "outputId": "46b9aba1-3623-445e-9a14-22cd83b4f115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dzM50pygphUe"
      },
      "outputs": [],
      "source": [
        "# Import essential libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNAzJi1c9WAX"
      },
      "source": [
        "Load the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLpOZlyZsi0D"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Use raw strings to avoid escape character issues\n",
        "zip_path = '/content/drive/MyDrive/CNN_assignment/data.zip'\n",
        "extract_path = '/content/dataset'\n",
        "\n",
        "# Check and extract the zip file\n",
        "if os.path.exists(zip_path) and zipfile.is_zipfile(zip_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(f\" Dataset extracted to: {extract_path}\")\n",
        "else:\n",
        "    print(\" Zip file not found or invalid format.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDp_EWxVOhUu"
      },
      "source": [
        "## **2. Data Preparation** <font color=red> [25 marks] </font><br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7Ac8VxvjWnw"
      },
      "source": [
        "### **2.1 Load and Preprocess Images** <font color=red> [8 marks] </font><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghmtINrMXDMy"
      },
      "source": [
        "Let us create a function to load the images first. We can then directly use this function while loading images of the different categories to load and crop them in a single step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZQ1UZNfQCWX"
      },
      "source": [
        "#### **2.1.1** <font color=red> [3 marks] </font><br>\n",
        "Create a function to load the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efdApxllCn7p"
      },
      "outputs": [],
      "source": [
        "def load_images_from_directory(base_dir, image_size=(128, 128)):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    # Directly iterate through subfolders of base_dir\n",
        "    for class_name in os.listdir(base_dir):  # Subfolders are class names\n",
        "        class_path = os.path.join(base_dir, class_name)\n",
        "        if os.path.isdir(class_path):  # Ensure it's a directory\n",
        "            for img_name in os.listdir(class_path):\n",
        "                img_path = os.path.join(class_path, img_name)\n",
        "                try:\n",
        "                    img = Image.open(img_path).convert('RGB')  # Make sure image is RGB\n",
        "                    img = img.resize(image_size)\n",
        "                    images.append(np.array(img))\n",
        "                    labels.append(class_name)\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Could not process file {img_path}: {e}\")\n",
        "\n",
        "    return images, labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J01VQrLhQsxx"
      },
      "source": [
        "#### **2.1.2** <font color=red> [5 marks] </font><br>\n",
        "Load images and labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOOzJGH3si0E"
      },
      "outputs": [],
      "source": [
        "# Load images and labels\n",
        "\n",
        "dataset_path = '/content/dataset/data'\n",
        "image_size = (128, 128)\n",
        "\n",
        "images, labels = load_images_from_directory(dataset_path, image_size)\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(f\"Total images loaded: {len(images)}\")\n",
        "print(f\"Unique labels found: {set(labels)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C9Oo0PTtYLf"
      },
      "source": [
        "Load the images from the dataset directory. Labels of images are present in the subdirectories.\n",
        "\n",
        "Verify if the images and labels are loaded correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm2zlZbmamzy"
      },
      "outputs": [],
      "source": [
        "# Convert labels to numpy array (if not already done)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Verify if data looks correct\n",
        "print(f\"Image data shape: {images.shape}\")\n",
        "print(f\"First 5 labels: {labels[:5]}\")\n",
        "\n",
        "# Show 5 sample images with labels\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.imshow(images[i].astype('uint8'))  # Ensures correct display\n",
        "    plt.title(labels[i])\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26Is-EwKuyGf"
      },
      "source": [
        "Perform any operations, if needed, on the images and labels to get them into the desired format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I64rs77bkAYk"
      },
      "source": [
        "### **2.2 Data Visualisation** <font color=red> [9 marks] </font><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCAepbyAQdI2"
      },
      "source": [
        "#### **2.2.1** <font color=red> [3 marks] </font><br>\n",
        "Create a bar plot to display the class distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gm5LuWSFqTac"
      },
      "outputs": [],
      "source": [
        "# Visualise Data Distribution\n",
        "\n",
        "# Convert labels list to a pandas Series for easier plotting\n",
        "label_series = pd.Series(labels)\n",
        "\n",
        "# Plot class distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x=label_series)\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNWsPfTzRh7x"
      },
      "source": [
        "#### **2.2.2** <font color=red> [3 marks] </font><br>\n",
        "Visualise some sample images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37yXZzfLyOWt"
      },
      "outputs": [],
      "source": [
        "# Visualise Sample Images (across different labels)\n",
        "import random\n",
        "\n",
        "# Get unique classes\n",
        "classes = sorted(set(labels))\n",
        "\n",
        "# Plot sample images from each class\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, class_name in enumerate(classes):\n",
        "    # Find indices where label == class_name\n",
        "    class_indices = [idx for idx, lbl in enumerate(labels) if lbl == class_name]\n",
        "    img_idx = random.choice(class_indices)\n",
        "\n",
        "    plt.subplot(2, 4, i+1)  # adjust rows/cols depending on number of classes\n",
        "    plt.imshow(images[img_idx])\n",
        "    plt.title(class_name)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.suptitle(\"Sample Images from Each Class\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqZW9BCtsi0F"
      },
      "source": [
        "Check for Image size consistency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wp_yKi0tsi0F"
      },
      "outputs": [],
      "source": [
        "# Check that all images have the same shape\n",
        "unique_shapes = set([img.shape for img in images])\n",
        "print(f\"Unique image shapes in dataset: {unique_shapes}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVXR2qG-E0Gm"
      },
      "source": [
        "Flatten all image pixels to view distribution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrxdFzNigaYG"
      },
      "source": [
        "#### **2.2.3** <font color=red> [3 marks] </font><br>\n",
        "Based on the smallest and largest image dimensions, resize the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyVvjNXqgIGe"
      },
      "outputs": [],
      "source": [
        "# Find the smallest and largest image dimensions from the data set\n",
        "# Gather width and height of all images\n",
        "widths = []\n",
        "heights = []\n",
        "\n",
        "for img in images:\n",
        "    h, w = img.shape[:2]\n",
        "    widths.append(w)\n",
        "    heights.append(h)\n",
        "\n",
        "# Find min and max\n",
        "min_w, max_w = min(widths), max(widths)\n",
        "min_h, max_h = min(heights), max(heights)\n",
        "\n",
        "print(f\"Smallest image dimensions: ({min_h}, {min_w})\")\n",
        "print(f\"Largest image dimensions: ({max_h}, {max_w})\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fz7EutUrgKFZ"
      },
      "outputs": [],
      "source": [
        "# Resize the image dimensions\n",
        "# Resize all images to a consistent shape (128, 128)\n",
        "resized_images = []\n",
        "\n",
        "for img in images:\n",
        "    img_resized = np.array(Image.fromarray((img * 255).astype(np.uint8)).resize(image_size))\n",
        "    # Normalize the resized image back to [0, 1]\n",
        "    img_resized = img_resized / 255.0\n",
        "    resized_images.append(img_resized)\n",
        "\n",
        "# Convert to numpy array\n",
        "resized_images = np.array(resized_images)\n",
        "\n",
        "print(f\"All images resized to: {resized_images[0].shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCB8uOckR5li"
      },
      "source": [
        "### **2.3 Encoding the classes** <font color=red> [3 marks] </font><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdC4dpTWt9eo"
      },
      "source": [
        "There are seven classes present in the data.\n",
        "\n",
        "\n",
        "\n",
        "We have extracted the images and their labels, and visualised their distribution. Now, we need to perform encoding on the labels. Encode the labels suitably."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Nwd0Ztvkf7K"
      },
      "source": [
        "####**2.3.1** <font color=red> [3 marks] </font><br>\n",
        "Encode the target class labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkyXDQN-660s"
      },
      "outputs": [],
      "source": [
        "# Encode the labels suitably\n",
        "# Get unique classes\n",
        "unique_classes = sorted(set(labels))\n",
        "label_to_index = {label: idx for idx, label in enumerate(unique_classes)}\n",
        "\n",
        "# Integer encode the labels\n",
        "encoded_labels = np.array([label_to_index[label] for label in labels])\n",
        "\n",
        "print(\"Label to index mapping:\", label_to_index)\n",
        "print(\"First 5 encoded labels:\", encoded_labels[:5])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBszUv40G-5w"
      },
      "outputs": [],
      "source": [
        "# Integer encoding for labels\n",
        "unique_classes = sorted(set(labels))\n",
        "label_to_index = {label: idx for idx, label in enumerate(unique_classes)}\n",
        "encoded_labels = np.array([label_to_index[label] for label in labels])\n",
        "\n",
        "# Plot encoded label distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x=encoded_labels)\n",
        "plt.title(\"Encoded Label Distribution\")\n",
        "plt.xlabel(\"Encoded Label\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(ticks=range(len(unique_classes)), labels=unique_classes, rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNBM4hsuSaoj"
      },
      "source": [
        "### **2.4 Data Splitting** <font color=red> [5 marks] </font><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0xw-Qlh29cZ"
      },
      "source": [
        "#### **2.4.1** <font color=red> [5 marks] </font><br>\n",
        "Split the dataset into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TErpx_JOkwjO"
      },
      "outputs": [],
      "source": [
        "# Assign specified parts of the dataset to train and validation sets\n",
        "\n",
        "num_classes = len(unique_classes)\n",
        "one_hot_labels = np.eye(num_classes)[encoded_labels]\n",
        "\n",
        "# Split the data\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    images, one_hot_labels, test_size=0.2, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Validation set shape:\", X_val.shape, y_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mILXPeY-X-zP"
      },
      "source": [
        "## **3. Model Building and Evaluation** <font color=red> [20 marks] </font><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E0afHwy5M_i"
      },
      "source": [
        "### **3.1 Model building and training** <font color=red> [15 marks] </font><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsu8K3tL5a5Q"
      },
      "source": [
        "#### **3.1.1** <font color=red> [10 marks] </font><br>\n",
        "Build and compile the model. Use 3 convolutional layers. Add suitable normalisation, dropout, and fully connected layers to the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awW9V2lmMK_d"
      },
      "source": [
        "Test out different configurations and report the results in conclusions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKfZDGtWKiXE"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_OW3kESd-JA"
      },
      "source": [
        "# Model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oD7-2EXdz_Cl"
      },
      "outputs": [],
      "source": [
        "# Build and compile the model\n",
        "model1 = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "model1.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JV8K06sRI7Y9"
      },
      "source": [
        "Add Augmentation to improve generalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECk8F63pIWaZ"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2  # 20% for validation\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow(\n",
        "    X_train, y_train,\n",
        "    batch_size=32,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow(\n",
        "    X_train, y_train,\n",
        "    batch_size=32,\n",
        "    subset='validation'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t4duT1wX5wS"
      },
      "source": [
        "#### **3.1.2** <font color=red> [5 marks] </font><br>\n",
        "Train the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcrEzo51Qj6w"
      },
      "source": [
        "Use appropriate metrics and callbacks as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMYA3_7MkSvu"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model1.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2MyJlpHKXpe"
      },
      "source": [
        "Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2U-yzXeKRMw"
      },
      "outputs": [],
      "source": [
        "checkpoint1 = ModelCheckpoint(\n",
        "    \"best_model1.keras\",\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stop1 = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr1 = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    min_lr=1e-5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCg9nVMRLFkB"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history1 = model1.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[checkpoint1, early_stop1, reduce_lr1]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9K8FXyN1LjB8"
      },
      "outputs": [],
      "source": [
        "def plot_history(history):\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n_zxj9IRbBD"
      },
      "source": [
        "# Model 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qAsXcc3Q_qs"
      },
      "outputs": [],
      "source": [
        "\n",
        "model2 = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "#Model 2 Summary\n",
        "\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X24shjGjTPho"
      },
      "outputs": [],
      "source": [
        "# Training Model 2\n",
        "\n",
        "# Compile the model1\n",
        "\n",
        "model2.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "checkpoint2 = ModelCheckpoint(\n",
        "    \"best_model2.keras\",\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stop2 = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr2 = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    min_lr=1e-5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trYCLU5wTou6"
      },
      "outputs": [],
      "source": [
        "# Train the model2\n",
        "history2 = model2.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[checkpoint2, early_stop2, reduce_lr2]\n",
        ")\n",
        "\n",
        "# Plot History of Model 2\n",
        "plot_history(history2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkaspDAMSLxb"
      },
      "source": [
        "# Model 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ywQiY5xSBjp"
      },
      "outputs": [],
      "source": [
        "model3 = Sequential([\n",
        "    Conv2D(16, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(7, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBX9saN5UAqG"
      },
      "outputs": [],
      "source": [
        "model3.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0t7ngmuUG4O"
      },
      "outputs": [],
      "source": [
        "# Training Model 3\n",
        "\n",
        "# Compile the model 3\n",
        "\n",
        "model3.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "\n",
        ")\n",
        "checkpoint3 = ModelCheckpoint(\n",
        "    \"best_model3.keras\",\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stop3 = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr3 = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    min_lr=1e-5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cbrNkeUdBbA"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Train the model3\n",
        "history3 = model3.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[checkpoint3, early_stop3, reduce_lr3]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltLgvcy0ybZW"
      },
      "outputs": [],
      "source": [
        "# Plot History of Model 3\n",
        "plot_history(history3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPEeFTgZybZW"
      },
      "source": [
        "# Model 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BG3dSQMOTi4A"
      },
      "outputs": [],
      "source": [
        "# Unsing BatchNormalization to handle data\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSS944kSybZW"
      },
      "outputs": [],
      "source": [
        "#Building Model 4\n",
        "\n",
        "model4 = Sequential()\n",
        "\n",
        "# 1st Convolutional Block\n",
        "model4.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=X_train.shape[1:]))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model4.add(Dropout(0.2))\n",
        "\n",
        "# 2nd Convolutional Block\n",
        "model4.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model4.add(Dropout(0.3))\n",
        "\n",
        "# 3rd Convolutional Block\n",
        "model4.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model4.add(Dropout(0.4))\n",
        "\n",
        "# Fully Connected Layers\n",
        "model4.add(Flatten())\n",
        "model4.add(Dense(256, activation='relu'))\n",
        "model4.add(Dropout(0.5))\n",
        "model4.add(Dense(128, activation='relu'))\n",
        "model4.add(Dropout(0.3))\n",
        "\n",
        "# Output Layer\n",
        "model4.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model Summary\n",
        "model4.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbxlvG7gybZW"
      },
      "outputs": [],
      "source": [
        "# Compile the model 4\n",
        "\n",
        "model4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "checkpoint4 = ModelCheckpoint( \"best_model4.keras\", monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "\n",
        "early_stop4 = EarlyStopping( monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1)\n",
        "\n",
        "reduce_lr4 = ReduceLROnPlateau( monitor='val_loss', factor=0.2, patience=3, verbose=1, min_lr=1e-5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffis3taRybZX"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Train the model4\n",
        "history4 = model4.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[checkpoint4, early_stop4, reduce_lr4]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8VQRD1oybZX"
      },
      "outputs": [],
      "source": [
        "# Plot History of Model 4\n",
        "plot_history(history4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xM03myjybZX"
      },
      "source": [
        "# Model 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSfMdF3kWKYt"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import  GlobalAveragePooling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWOqMVsSybZX"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model5 = Sequential()\n",
        "\n",
        "# Conv Block 1\n",
        "model5.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(128, 128, 3)))\n",
        "model5.add(BatchNormalization())\n",
        "model5.add(MaxPooling2D((2, 2)))\n",
        "model5.add(Dropout(0.2))\n",
        "\n",
        "# Conv Block 2\n",
        "model5.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model5.add(BatchNormalization())\n",
        "model5.add(MaxPooling2D((2, 2)))\n",
        "model5.add(Dropout(0.3))\n",
        "\n",
        "# Conv Block 3\n",
        "model5.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model5.add(BatchNormalization())\n",
        "model5.add(MaxPooling2D((2, 2)))\n",
        "model5.add(Dropout(0.4))\n",
        "\n",
        "# Replace Flatten with GAP to reduce overfitting\n",
        "model5.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Fully connected layers\n",
        "model5.add(Dense(128, activation='relu'))\n",
        "model5.add(Dropout(0.4))\n",
        "model5.add(Dense(num_classes, activation='softmax'))  # Replace `num_classes` with your actual output size\n",
        "\n",
        "# Compile\n",
        "model5.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model5.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZpqZ4xaybZX"
      },
      "outputs": [],
      "source": [
        "# Define callbacks\n",
        "checkpoint5 = ModelCheckpoint( 'best_model5.keras', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "\n",
        "earlystop5 = EarlyStopping( monitor='val_loss', patience=7, restore_best_weights=True, verbose=1)\n",
        "\n",
        "reduce_lr5 = ReduceLROnPlateau( monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=1)\n",
        "\n",
        "callbacks_list = [checkpoint5, earlystop5, reduce_lr5]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rpJBM_5ybZX"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history5 = model5.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=40,\n",
        "    batch_size=32,\n",
        "    callbacks=callbacks_list,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmK0H1L3ybZX"
      },
      "outputs": [],
      "source": [
        "# Plot History of Model 5\n",
        "\n",
        "plot_history(history5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbuVV0eQybZX"
      },
      "source": [
        "# Model 6"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "metadata": {
        "id": "vJfO-eFHYzWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdBvUwjTybZX"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Build Model 6\n",
        "model6 = Sequential()\n",
        "\n",
        "# Conv Block 1\n",
        "model6.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(128, 128, 3)))\n",
        "model6.add(BatchNormalization())\n",
        "model6.add(MaxPooling2D((2, 2)))\n",
        "model6.add(Dropout(0.25))\n",
        "\n",
        "# Conv Block 2\n",
        "model6.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model6.add(BatchNormalization())\n",
        "model6.add(MaxPooling2D((2, 2)))\n",
        "model6.add(Dropout(0.3))\n",
        "\n",
        "# Conv Block 3\n",
        "model6.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model6.add(BatchNormalization())\n",
        "model6.add(MaxPooling2D((2, 2)))\n",
        "model6.add(Dropout(0.4))\n",
        "\n",
        "# GAP + Dense Layers\n",
        "model6.add(GlobalAveragePooling2D())\n",
        "model6.add(Dense(256, kernel_regularizer=l2(0.001)))\n",
        "model6.add(LeakyReLU(alpha=0.1))\n",
        "model6.add(Dropout(0.5))\n",
        "model6.add(Dense(128, kernel_regularizer=l2(0.001)))\n",
        "model6.add(LeakyReLU(alpha=0.1))\n",
        "model6.add(Dropout(0.4))\n",
        "model6.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile model with SGD + momentum\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
        "model6.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model6.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "My-3QfcjD8S3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Callbacks\n",
        "checkpoint6 = ModelCheckpoint( 'best_model6.keras',monitor='val_accuracy',save_best_only=True,verbose=1)\n",
        "\n",
        "earlystop6 = EarlyStopping(monitor='val_loss',patience=7,restore_best_weights=True,verbose=1)\n",
        "reduce_lr6 = ReduceLROnPlateau(monitor='val_loss',factor=0.2,patience=3,min_lr=1e-6,verbose=1)\n",
        "\n",
        "callbacks_list6 = [checkpoint6, earlystop6, reduce_lr6]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfTN1hTlybZX"
      },
      "outputs": [],
      "source": [
        "#Train Model 6\n",
        "history6 = model6.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=40,\n",
        "    callbacks=callbacks_list6,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FlleCGoybZX"
      },
      "outputs": [],
      "source": [
        "#Plot History of Model 6\n",
        "plot_history(history6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5jNJNZiybZX"
      },
      "source": [
        "Model 6 :\n",
        "\n",
        "* Data Augmentation using ImageDataGenerator to improve generalization.\n",
        "* Optimizer switched to SGD with momentum (0.9) for more stable convergence.\n",
        "* Activation Function in dense layers changed to LeakyReLU for better gradient flow.\n",
        "* Callbacks remain similar to previous models but tuned for robustness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzSmsAcoG0zU"
      },
      "source": [
        "# Model 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyhSxcTpJxO0"
      },
      "outputs": [],
      "source": [
        "# Build Model 7\n",
        "model7 = Sequential()\n",
        "\n",
        "# Conv Block 1\n",
        "model7.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(128, 128, 3)))\n",
        "model7.add(BatchNormalization())\n",
        "model7.add(MaxPooling2D((2, 2)))\n",
        "model7.add(Dropout(0.25))\n",
        "\n",
        "# Conv Block 2\n",
        "model7.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model7.add(BatchNormalization())\n",
        "model7.add(MaxPooling2D((2, 2)))\n",
        "model7.add(Dropout(0.3))\n",
        "\n",
        "# Conv Block 3\n",
        "model7.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model7.add(BatchNormalization())\n",
        "model7.add(MaxPooling2D((2, 2)))\n",
        "model7.add(Dropout(0.4))\n",
        "\n",
        "# GAP + Dense Layers\n",
        "model7.add(GlobalAveragePooling2D())\n",
        "model7.add(Dense(256, kernel_regularizer=l2(0.001)))\n",
        "model7.add(LeakyReLU(alpha=0.1))\n",
        "model7.add(Dropout(0.5))\n",
        "model7.add(Dense(128, kernel_regularizer=l2(0.001)))\n",
        "model7.add(LeakyReLU(alpha=0.1))\n",
        "model7.add(Dropout(0.4))\n",
        "model7.add(Dense(num_classes, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgihzFTyNbGe"
      },
      "outputs": [],
      "source": [
        "# Compile model with SGD + momentum\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
        "model7.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model7.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ir9WrnGNksE"
      },
      "outputs": [],
      "source": [
        "# Callbacks\n",
        "checkpoint7 = ModelCheckpoint('best_model7.keras', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "earlystop7 = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
        "reduce_lr7 = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=1)\n",
        "\n",
        "callbacks_list7 = [checkpoint7, earlystop7, reduce_lr7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6OvfknJNnxX"
      },
      "outputs": [],
      "source": [
        "# Compute class weights\n",
        "class_weights7 = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(np.argmax(y_train, axis=1)), y=np.argmax(y_train, axis=1))\n",
        "class_weights7 = dict(enumerate(class_weights8))\n",
        "\n",
        "# Train Model 7\n",
        "history7 = model7.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator\n",
        "    epochs=40,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weights7,\n",
        "    callbacks=callbacks_list7,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWT-bIj9YVzh"
      },
      "source": [
        "### **3.2 Model Testing and Evaluation** <font color=red> [5 marks] </font><br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjhU3i5v59d6"
      },
      "source": [
        "#### **3.2.1** <font color=red> [5 marks] </font><br>\n",
        "Evaluate the model on test dataset. Derive appropriate metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_MtfUM_4y7j",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Evaluate on the test set; display suitable metrics\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Load models\n",
        "model1 = tf.keras.models.load_model(\"best_model1.keras\")\n",
        "model2 = tf.keras.models.load_model(\"best_model2.keras\")\n",
        "model3 = tf.keras.models.load_model(\"best_model3.keras\")\n",
        "model4 = tf.keras.models.load_model(\"best_model4.keras\")\n",
        "model5 = tf.keras.models.load_model(\"best_model5.keras\")\n",
        "model6 = tf.keras.models.load_model(\"best_model6.keras\")\n",
        "model7 = tf.keras.models.load_model(\"best_model7.keras\")\n",
        "\n",
        "# Evaluate on test set\n",
        "loss1, acc1 = model1.evaluate(X_val, y_val, verbose=0)\n",
        "loss2, acc2 = model2.evaluate(X_val, y_val, verbose=0)\n",
        "loss3, acc3 = model3.evaluate(X_val, y_val, verbose=0)\n",
        "loss4, acc4 = model4.evaluate(X_val, y_val, verbose=0)\n",
        "loss5, acc5 = model5.evaluate(X_val, y_val, verbose=0)\n",
        "loss6, acc6 = model6.evaluate(X_val, y_val, verbose=0)\n",
        "loss7, acc7 = model7.evaluate(X_val, y_val, verbose=0)\n",
        "\n",
        "print(f\"Model 1 - Accuracy: {acc1:.2f}, Loss: {loss1:.4f}\")\n",
        "print(f\"Model 2 - Accuracy: {acc2:.2f}, Loss: {loss2:.4f}\")\n",
        "print(f\"Model 2 - Accuracy: {acc3:.2f}, Loss: {loss3:.4f}\")\n",
        "print(f\"Model 4 - Accuracy: {acc4:.2f}, Loss: {loss4:.4f}\")\n",
        "print(f\"Model 5 - Accuracy: {acc5:.2f}, Loss: {loss5:.4f}\")\n",
        "print(f\"Model 6 - Accuracy: {acc6:.2f}, Loss: {loss6:.4f}\")\n",
        "print(f\"Model 7 - Accuracy: {acc7:.2f}, Loss: {loss7:.4f}\")\n",
        "\n",
        "# Get predictions\n",
        "y_pred1 = model1.predict(X_val)\n",
        "y_pred2 = model2.predict(X_val)\n",
        "y_pred3 = model3.predict(X_val)\n",
        "y_pred4 = model4.predict(X_val)\n",
        "y_pred5 = model5.predict(X_val)\n",
        "y_pred6 = model6.predict(X_val)\n",
        "y_pred7 = model7.predict(X_val)\n",
        "\n",
        "# Convert predictions to labels\n",
        "y_pred_labels1 = np.argmax(y_pred1, axis=1)\n",
        "y_pred_labels2 = np.argmax(y_pred2, axis=1)\n",
        "y_pred_labels3 = np.argmax(y_pred3, axis=1)\n",
        "y_pred_labels4 = np.argmax(y_pred4, axis=1)\n",
        "y_pred_labels5 = np.argmax(y_pred5, axis=1)\n",
        "y_pred_labels6 = np.argmax(y_pred6, axis=1)\n",
        "y_pred_labels7 = np.argmax(y_pred7, axis=1)\n",
        "y_true = np.argmax(y_val, axis=1)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y526ZngHFXsi"
      },
      "outputs": [],
      "source": [
        "# Classification Reports\n",
        "print(\"\\nClassification Report for Model 1\")\n",
        "print(classification_report(y_true, y_pred_labels1))\n",
        "\n",
        "print(\"\\nClassification Report for Model 2\")\n",
        "print(classification_report(y_true, y_pred_labels2))\n",
        "\n",
        "print(\"\\nClassification Report for Model 3\")\n",
        "print(classification_report(y_true, y_pred_labels3))\n",
        "\n",
        "print(\"\\nClassification Report for Model 4\")\n",
        "print(classification_report(y_true, y_pred_labels4))\n",
        "\n",
        "print(\"\\nClassification Report for Model 5\")\n",
        "print(classification_report(y_true, y_pred_labels5))\n",
        "\n",
        "print(\"\\nClassification Report for Model 6\")\n",
        "print(classification_report(y_true, y_pred_labels6))\n",
        "\n",
        "print(\"\\nClassification Report for Model 7\")\n",
        "print(classification_report(y_true, y_pred_labels7))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByJsH6JOFUWx"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrices\n",
        "fig, ax = plt.subplots(4, 2, figsize=(14, 6))\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_true, y_pred_labels1, ax=ax[0], cmap=\"Blues\", colorbar=False)\n",
        "ax[0].set_title(\"Model 1 - Confusion Matrix\")\n",
        "ConfusionMatrixDisplay.from_predictions(y_true, y_pred_labels2, ax=ax[1], cmap=\"Greens\", colorbar=False)\n",
        "ax[1].set_title(\"Model 2 - Confusion Matrix\")\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_true, y_pred_labels3, ax=ax[0], cmap=\"Blues\", colorbar=False)\n",
        "ax[0].set_title(\"Model 3 - Confusion Matrix\")\n",
        "ConfusionMatrixDisplay.from_predictions(y_true, y_pred_labels4, ax=ax[1], cmap=\"Greens\", colorbar=False)\n",
        "ax[1].set_title(\"Model 4 - Confusion Matrix\")\n",
        "\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_true, y_pred_labels5, ax=ax[0], cmap=\"Blues\", colorbar=False)\n",
        "ax[0].set_title(\"Model 5 - Confusion Matrix\")\n",
        "ConfusionMatrixDisplay.from_predictions(y_true, y_pred_labels6, ax=ax[1], cmap=\"Greens\", colorbar=False)\n",
        "ax[1].set_title(\"Model 6 - Confusion Matrix\")\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_true, y_pred_labels7, ax=ax[0], cmap=\"Blues\", colorbar=False)\n",
        "ax[0].set_title(\"Model 7 - Confusion Matrix\")\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPy_G8nTybZY"
      },
      "source": [
        "# Comparing Models for test_loss and test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7w1xlnELI4dG"
      },
      "outputs": [],
      "source": [
        "# Evaluate on test data\n",
        "test_loss, test_accuracy = model1.evaluate(X_val, y_val, verbose=1)\n",
        "\n",
        "print(f\" Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\" Test Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEJcLgMTI4Qk"
      },
      "outputs": [],
      "source": [
        "# Evaluate on test data\n",
        "test_loss, test_accuracy = model2.evaluate(X_val, y_val, verbose=1)\n",
        "\n",
        "print(f\" Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\" Test Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGS0weM9I4Fq"
      },
      "outputs": [],
      "source": [
        "# Evaluate on test data\n",
        "test_loss, test_accuracy = model3.evaluate(X_val, y_val, verbose=1)\n",
        "\n",
        "print(f\" Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\" Test Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKX1sISgI37R"
      },
      "outputs": [],
      "source": [
        "# Evaluate on test data\n",
        "test_loss, test_accuracy = model4.evaluate(X_val, y_val, verbose=1)\n",
        "\n",
        "print(f\" Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\" Test Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otByZqs5I3vt"
      },
      "outputs": [],
      "source": [
        "# Evaluate on test data\n",
        "test_loss, test_accuracy = model5.evaluate(X_val, y_val, verbose=1)\n",
        "\n",
        "print(f\" Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\" Test Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qK4y9sEybZY"
      },
      "outputs": [],
      "source": [
        "# Evaluate on test data\n",
        "test_loss, test_accuracy = model6.evaluate(X_val, y_val, verbose=1)\n",
        "\n",
        "print(f\" Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\" Test Loss: {test_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utro5JdHS0JM"
      },
      "source": [
        "## **4. Data Augmentation** <font color=red> [optional] </font><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T6QlG4eS4xi"
      },
      "source": [
        "#### **4.1 Create a Data Augmentation Pipeline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AXlfuoa4jQV"
      },
      "source": [
        "##### **4.1.1**\n",
        "Define augmentation steps for the datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07i11vgMEmM2"
      },
      "source": [
        "Augment and resample the images.\n",
        "In case of class imbalance, you can also perform adequate undersampling on the majority class and augment those images to ensure consistency in the input datasets for both classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chvmgE2r4xPZ"
      },
      "source": [
        "Augment the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-JBheeYFS8d"
      },
      "outputs": [],
      "source": [
        "# Create a function to augment the images\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ddy1y1nPIlvM"
      },
      "outputs": [],
      "source": [
        "# Create the augmented training dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZYekkw9TCvP"
      },
      "source": [
        "##### **4.1.2**\n",
        "\n",
        "Train the model on the new augmented dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBcRbt57FEct"
      },
      "outputs": [],
      "source": [
        "# Train the model using augmented images\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFPuXAvHkJVz"
      },
      "source": [
        "## **5. Conclusions** <font color = red> [5 marks]</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33tWCHjpO5hH"
      },
      "source": [
        "#### **5.1 Conclude with outcomes and insights gained** <font color =red> [5 marks] </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3e1TLo2kWi0"
      },
      "source": [
        "* Report your findings about the data\n",
        "* Report model training results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WSSMb4-ybZZ"
      },
      "source": [
        "## Model 5:\n",
        "\n",
        "* Accuracy: 61%\n",
        "* Loss: 1.0950\n",
        "\n",
        "#### Strengths:\n",
        "* Solid performance across most classes.\n",
        "* High recall for majority classes like class 1 and class 6.\n",
        "* Used Batch Normalization, Dropout, and Global Average Pooling effectively.\n",
        "\n",
        "#### Weaknesses:\n",
        "* Lower precision/recall for minority classes (e.g., class 4 and class 5).\n",
        "* Slight signs of overfitting mitigated by early stopping.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGvMHMfEybZZ"
      },
      "source": [
        "## Model 6:\n",
        "* Accuracy: 50%\n",
        "* Loss: 1.5736\n",
        "\n",
        "#### Strengths:\n",
        "Attempted deeper architecture with more dropout.\n",
        "\n",
        "#### Weaknesses:\n",
        "\n",
        "* Underperformed despite more aggressive dropout.\n",
        "* Model complexity may have led to underfitting.\n",
        "* Less balanced performance across classes.\n",
        "* Recall dropped significantly for certain classes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB_gYsbEybZZ"
      },
      "source": [
        "## Classification Metrics Summary\n",
        "\n",
        "Model 5\n",
        " Accuracy: 61%\n",
        " Macro Avg F1: ~0.60\n",
        " Weakest Class: Class 4 & 5\n",
        " Confusion Matrix: Moderate confusion in minority classes\n",
        "    \n",
        "Model 6\n",
        " Accuracy:50%\n",
        " Macro Avg F1: ~0.48\n",
        " Weakest Class: Class 4 & 3\n",
        " Confusion Matrix: Higher misclassification\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN-hZqUwybZZ"
      },
      "source": [
        "## Key Learnings and Takeaways\n",
        "\n",
        "* Data augmentation and class weights dramatically improved performance under class imbalance.\n",
        "* LeakyReLU activation in deeper layers helped prevent dead neurons and improved non-linear modeling.\n",
        "* Model complexity is not always better ‚Äî Model 6 tried to go deeper but lacked regularization balance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCNnlde4ybZZ"
      },
      "source": [
        "## Final Verdict\n",
        "* Model5 is the best-performing model in terms of:\n",
        "Overall accuracy\n",
        "Balanced performance across classes\n",
        "Handling class imbalance\n",
        "Model generalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlJgGpO7ybZZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}